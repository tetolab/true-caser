{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/toniga/miniconda3/envs/ml/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator, pad_sequences\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.layers.core import Activation, Dropout, Dense, Flatten\n",
    "from keras.layers import TimeDistributed, Bidirectional, InputLayer, GlobalMaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.metrics import categorical_accuracy\n",
    "from IPython.display import clear_output\n",
    "from more_itertools import flatten, intersperse\n",
    "import random\n",
    "\n",
    "import os\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from batcher import batch_from_generator\n",
    "from train_data import load_conll2003, create_conll_encoded_shifted_generator\n",
    "from mappings import get_all_mappings\n",
    "from corpus import corpus_training_data_generator, create_all_corpus_train_pipeline, pad, encode_each_sentence\n",
    "from model import create_model, compile_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROPOUT = 0.2\n",
    "TIME_SLICE_SIZE = 128\n",
    "BATCH_SIZE = 512\n",
    "SAMPLING_RATE = 1\n",
    "PADDING = 0\n",
    "UNKNOWN = 1\n",
    "NUM_OF_UNITS = 250\n",
    "WORDS_PER_BATCH = 100\n",
    "EPOCHS=1\n",
    "MODEL_SAVE_PATH = 'tc_model.h5'\n",
    "LSTM_MODEL_SAVE_PATH = 'lstm_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping, reverse_mapping, lower_mapping, lower_reverse_mapping = get_all_mappings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_model(shape, classes):\n",
    "#     # First layer inputs must be 3D\n",
    "#     # with shape (samples, timesteps, features)\n",
    "#     model = Sequential()\n",
    "#     model.add(InputLayer(input_shape=shape))\n",
    "#     model.add(Bidirectional(LSTM(NUM_OF_UNITS, return_sequences=True, dropout=DROPOUT, recurrent_dropout=DROPOUT)))\n",
    "#     model.add(TimeDistributed(Dense(1000)))\n",
    "#     model.add(TimeDistributed(Dense(classes)))\n",
    "#     model.add(Activation('softmax'))\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(len(mapping), NUM_OF_UNITS, DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = compile_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(MODEL_SAVE_PATH): \n",
    "    model.load_weights(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_board = TensorBoard(batch_size=BATCH_SIZE, write_graph=False, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = create_all_corpus_train_pipeline(TIME_SLICE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37666 samples, validate on 9417 samples\n",
      "Epoch 1/1\n",
      " - 369s - loss: 0.3138 - acc: 0.9469 - val_loss: 0.1712 - val_acc: 0.9568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x132f7b240>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#g = corpus_training_data_generator('gutenberg',TIME_SLICE_SIZE, BATCH_SIZE, shift=False)\n",
    "model.fit(X, Y,  verbose=2, validation_split=0.2, callbacks=[tensor_board], batch_size=200, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i want to go on holiday to france'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence = pad([\"I want to go on holiday to France\".lower()], TIME_SLICE_SIZE)\n",
    "test_sentence = encode_each_sentence(test_sentence, mapping)\n",
    "\n",
    "mapped_sentence = np.asarray(test_sentence)\n",
    "predicted_result = model.predict_classes(mapped_sentence)[0]\n",
    "predicted_result = list(zip(pad([\"I want to go on holiday to France\".lower()], TIME_SLICE_SIZE)[0], predicted_result.tolist()))\n",
    "\n",
    "def true_case(letter, label):\n",
    "    if letter == 0:\n",
    "        return ''\n",
    "    if(label == 2):\n",
    "        return letter.lower()\n",
    "    if (label == 3):\n",
    "        return letter.upper()\n",
    "    if (label == 0):\n",
    "        return ''\n",
    "    return letter\n",
    "\n",
    "predicted_result = [true_case(letter, label) for letter, label in predicted_result]\n",
    "''.join(predicted_result) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"big_lstm.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
