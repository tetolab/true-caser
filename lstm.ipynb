{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator, pad_sequences\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.layers.core import Activation, Dropout, Dense, Flatten\n",
    "from keras.layers import TimeDistributed, Bidirectional, InputLayer, GlobalMaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.metrics import categorical_accuracy\n",
    "from IPython.display import clear_output\n",
    "from more_itertools import flatten, intersperse\n",
    "import random\n",
    "\n",
    "import os\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\Todd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n",
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     C:\\Users\\Todd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Todd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from batcher import batch_from_generator\n",
    "from train_data import load_conll2003, create_conll_encoded_shifted_generator\n",
    "from mappings import get_all_mappings, gen_input_feature_to_class_map, gen_input_feature_to_int_map\n",
    "from corpus import corpus_training_data_generator, create_all_corpus_train_pipeline, pad, encode_each_sentence\n",
    "from model import create_model, compile_model\n",
    "from metrics import F1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROPOUT = 0.25\n",
    "TIME_SLICE_SIZE = 100\n",
    "BATCH_SIZE = 512\n",
    "SAMPLING_RATE = 1\n",
    "OUTPUT_CLASSES = 2\n",
    "PADDING = 0\n",
    "UNKNOWN = 1\n",
    "NUM_OF_UNITS = 300\n",
    "EPOCHS=10000\n",
    "MODEL_SAVE_PATH = 'tc_model.h5'\n",
    "LSTM_MODEL_SAVE_PATH = 'lstm_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping, reverse_mapping, lower_mapping, lower_reverse_mapping = get_all_mappings()\n",
    "input_feature_to_class_map = gen_input_feature_to_class_map()\n",
    "input_feature_to_int_map = gen_input_feature_to_int_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(1, 2, NUM_OF_UNITS, DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = compile_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(MODEL_SAVE_PATH): \n",
    "    model.load_weights(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_board = TensorBoard(batch_size=BATCH_SIZE, write_graph=False, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, W = create_all_corpus_train_pipeline(TIME_SLICE_SIZE, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, Y_val, W_val = create_all_corpus_train_pipeline(TIME_SLICE_SIZE, 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_sample_weights(Ys):\n",
    "#     W = Ys * 49\n",
    "#     W = W + 1\n",
    "#     W = W.reshape((-1, TIME_SLICE_SIZE))\n",
    "#     return W\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W = get_sample_weights(Y)\n",
    "# W_val = get_sample_weights(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score = F1Score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 221877 samples, validate on 22367 samples\n",
      "Epoch 1/10000\n",
      "221877/221877 [==============================] - 315s 1ms/step - loss: 0.3083 - acc: 0.7950 - val_loss: 0.2087 - val_acc: 0.9068\n",
      "- precision: 0.23848562695719028 - recall: 0.921301595120467 - f1 score: 0.3788922387597269\n",
      "Epoch 2/10000\n",
      "221877/221877 [==============================] - 317s 1ms/step - loss: 0.2069 - acc: 0.8999 - val_loss: 0.1992 - val_acc: 0.9324\n",
      "- precision: 0.3053657379964434 - recall: 0.932935398345479 - f1 score: 0.46012475973390304\n",
      "Epoch 3/10000\n",
      "221877/221877 [==============================] - 316s 1ms/step - loss: 0.1906 - acc: 0.9172 - val_loss: 0.1895 - val_acc: 0.9332\n",
      "- precision: 0.30885387446155016 - recall: 0.9411355635078162 - f1 score: 0.46508131405517833\n",
      "Epoch 4/10000\n",
      "221877/221877 [==============================] - 318s 1ms/step - loss: 0.1775 - acc: 0.9285 - val_loss: 0.1929 - val_acc: 0.9344\n",
      "- precision: 0.31320674821237815 - recall: 0.9430189936687771 - f1 score: 0.47023381652284163\n",
      "Epoch 5/10000\n",
      "221877/221877 [==============================] - 317s 1ms/step - loss: 0.1662 - acc: 0.9361 - val_loss: 0.2205 - val_acc: 0.8912\n",
      "- precision: 0.21234363454027236 - recall: 0.9325732002376019 - f1 score: 0.3459220386985133\n",
      "Epoch 6/10000\n",
      "221877/221877 [==============================] - 318s 1ms/step - loss: 0.1550 - acc: 0.9427 - val_loss: 0.2714 - val_acc: 0.8441\n",
      "- precision: 0.14627457726596574 - recall: 0.8376917838981209 - f1 score: 0.24905935081745484\n",
      "Epoch 7/10000\n",
      "221877/221877 [==============================] - 316s 1ms/step - loss: 0.1463 - acc: 0.9464 - val_loss: 0.3114 - val_acc: 0.8546\n",
      "- precision: 0.15693035617642173 - recall: 0.8486011909073787 - f1 score: 0.26487739251353826\n",
      "Epoch 8/10000\n",
      "221877/221877 [==============================] - 316s 1ms/step - loss: 0.1385 - acc: 0.9502 - val_loss: 0.3242 - val_acc: 0.8285\n",
      "- precision: 0.1291567730967208 - recall: 0.793576054358692 - f1 score: 0.22215687865022712\n",
      "Epoch 9/10000\n",
      "221877/221877 [==============================] - 314s 1ms/step - loss: 0.1317 - acc: 0.9528 - val_loss: 0.3136 - val_acc: 0.8679\n",
      "- precision: 0.15776772429810448 - recall: 0.7558350115178998 - f1 score: 0.2610464374441767\n",
      "Epoch 10/10000\n",
      "221877/221877 [==============================] - 317s 1ms/step - loss: 0.1264 - acc: 0.9555 - val_loss: 0.2887 - val_acc: 0.9031\n",
      "- precision: 0.2094422560042186 - recall: 0.7710763078973676 - f1 score: 0.3294092889681125\n",
      "Epoch 11/10000\n",
      "221877/221877 [==============================] - 318s 1ms/step - loss: 0.1193 - acc: 0.9579 - val_loss: 0.3217 - val_acc: 0.9100\n",
      "- precision: 0.21718425083649245 - recall: 0.7353925503093172 - f1 score: 0.3353339697493204\n",
      "Epoch 12/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.1142 - acc: 0.9595 - val_loss: 0.3090 - val_acc: 0.8864\n",
      "- precision: 0.1965654365058533 - recall: 0.8679715457166451 - f1 score: 0.32053974377151845\n",
      "Epoch 13/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.1092 - acc: 0.9618 - val_loss: 0.3191 - val_acc: 0.8804\n",
      "- precision: 0.19014788481603428 - recall: 0.8818654651348101 - f1 score: 0.31284097888404344\n",
      "Epoch 14/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.1047 - acc: 0.9635 - val_loss: 0.3115 - val_acc: 0.8947\n",
      "- precision: 0.20033976022429933 - recall: 0.8064413311504861 - f1 score: 0.3209481471230965\n",
      "Epoch 15/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.1011 - acc: 0.9648 - val_loss: 0.3251 - val_acc: 0.8684\n",
      "- precision: 0.17234589588919977 - recall: 0.8585109311388958 - f1 score: 0.2870637932997295\n",
      "Epoch 16/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.0974 - acc: 0.9660 - val_loss: 0.3595 - val_acc: 0.8614\n",
      "- precision: 0.16376675255213843 - recall: 0.8499485678686814 - f1 score: 0.27462013050845874\n",
      "Epoch 17/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.0946 - acc: 0.9671 - val_loss: 0.2909 - val_acc: 0.8870\n",
      "- precision: 0.19862768829107177 - recall: 0.8773742085971343 - f1 score: 0.32392286913963253\n",
      "Epoch 18/10000\n",
      "221877/221877 [==============================] - 313s 1ms/step - loss: 0.0916 - acc: 0.9680 - val_loss: 0.3255 - val_acc: 0.8908\n",
      "- precision: 0.1990853281694203 - recall: 0.8400678034857946 - f1 score: 0.32188744708902917\n",
      "Epoch 19/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.0883 - acc: 0.9690 - val_loss: 0.3170 - val_acc: 0.8891\n",
      "- precision: 0.20320947793773972 - recall: 0.8881387363632413 - f1 score: 0.330743582273154\n",
      "Epoch 20/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.0861 - acc: 0.9698 - val_loss: 0.3468 - val_acc: 0.8925\n",
      "- precision: 0.20282464119563295 - recall: 0.8470220071570346 - f1 score: 0.3272800555319197\n",
      "Epoch 21/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.0834 - acc: 0.9706 - val_loss: 0.3000 - val_acc: 0.9116\n",
      "- precision: 0.24036693548387097 - recall: 0.8636396563464352 - f1 score: 0.3760673515801693\n",
      "Epoch 22/10000\n",
      "221877/221877 [==============================] - 313s 1ms/step - loss: 0.0818 - acc: 0.9712 - val_loss: 0.3459 - val_acc: 0.8739\n",
      "- precision: 0.18380276881329363 - recall: 0.8969329064224969 - f1 score: 0.3050861656884631\n",
      "Epoch 23/10000\n",
      "221877/221877 [==============================] - 313s 1ms/step - loss: 0.0795 - acc: 0.9718 - val_loss: 0.3300 - val_acc: 0.8858\n",
      "- precision: 0.20017626473161443 - recall: 0.9016414818248989 - f1 score: 0.32761720261424143\n",
      "Epoch 24/10000\n",
      "221877/221877 [==============================] - 313s 1ms/step - loss: 0.0774 - acc: 0.9723 - val_loss: 0.3937 - val_acc: 0.8629\n",
      "- precision: 0.1728511697855439 - recall: 0.9091896903930574 - f1 score: 0.29047794279313366\n",
      "Epoch 25/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.0758 - acc: 0.9730 - val_loss: 0.3685 - val_acc: 0.8864\n",
      "- precision: 0.19911570645879154 - recall: 0.8866754560074178 - f1 score: 0.32520251762149066\n",
      "Epoch 26/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.0738 - acc: 0.9735 - val_loss: 0.3846 - val_acc: 0.8634\n",
      "- precision: 0.1714713455230244 - recall: 0.8944120075916724 - f1 score: 0.28777263468001696\n",
      "Epoch 27/10000\n",
      "221877/221877 [==============================] - 313s 1ms/step - loss: 0.0719 - acc: 0.9740 - val_loss: 0.3701 - val_acc: 0.8794\n",
      "- precision: 0.18749980548198453 - recall: 0.8728250003621981 - f1 score: 0.30868752081572004\n",
      "Epoch 28/10000\n",
      "221877/221877 [==============================] - 313s 1ms/step - loss: 0.0741 - acc: 0.9746 - val_loss: 0.3870 - val_acc: 0.8869\n",
      "- precision: 0.2000045663887693 - recall: 0.8883850310765976 - f1 score: 0.32650268495864077\n",
      "Epoch 29/10000\n",
      "221877/221877 [==============================] - 313s 1ms/step - loss: 0.0700 - acc: 0.9746 - val_loss: 0.4143 - val_acc: 0.8337\n",
      "- precision: 0.1464290048260476 - recall: 0.9090592990742217 - f1 score: 0.2522295093170073\n",
      "Epoch 30/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.0674 - acc: 0.9752 - val_loss: 0.4192 - val_acc: 0.8705\n",
      "- precision: 0.17192675717947345 - recall: 0.8376917838981209 - f1 score: 0.28529910270422293\n",
      "Epoch 31/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.0658 - acc: 0.9753 - val_loss: 0.3865 - val_acc: 0.8975\n",
      "- precision: 0.2110546057851836 - recall: 0.847789867145734 - f1 score: 0.33797212106860575\n",
      "Epoch 32/10000\n",
      "221877/221877 [==============================] - 313s 1ms/step - loss: 0.0662 - acc: 0.9759 - val_loss: 0.4445 - val_acc: 0.8783\n",
      "- precision: 0.18154671446163295 - recall: 0.8394158468916159 - f1 score: 0.29852845704392994\n",
      "Epoch 33/10000\n",
      "221877/221877 [==============================] - 313s 1ms/step - loss: 0.0646 - acc: 0.9764 - val_loss: 0.4052 - val_acc: 0.8811\n",
      "- precision: 0.1877921320167177 - recall: 0.8579893658635527 - f1 score: 0.3081401852868408\n",
      "Epoch 34/10000\n",
      "221877/221877 [==============================] - 313s 1ms/step - loss: 0.0619 - acc: 0.9767 - val_loss: 0.3706 - val_acc: 0.9036\n",
      "- precision: 0.2250705841329119 - recall: 0.8696666328615099 - f1 score: 0.3575951817851462\n",
      "Epoch 35/10000\n",
      "221877/221877 [==============================] - 313s 1ms/step - loss: 0.0608 - acc: 0.9771 - val_loss: 0.4203 - val_acc: 0.8785\n",
      "- precision: 0.19279623782656913 - recall: 0.9218231603958101 - f1 score: 0.3188963650716084\n",
      "Epoch 36/10000\n",
      "221877/221877 [==============================] - 313s 1ms/step - loss: 0.0600 - acc: 0.9774 - val_loss: 0.4242 - val_acc: 0.8980\n",
      "- precision: 0.21437542613126637 - recall: 0.865508598583081 - f1 score: 0.34363648390965595\n",
      "Epoch 37/10000\n",
      "221877/221877 [==============================] - 313s 1ms/step - loss: 0.0584 - acc: 0.9777 - val_loss: 0.3946 - val_acc: 0.8920\n",
      "- precision: 0.20336232123269066 - recall: 0.856815843994031 - f1 score: 0.3287071260636849\n",
      "Epoch 38/10000\n",
      "221877/221877 [==============================] - 313s 1ms/step - loss: 0.0574 - acc: 0.9780 - val_loss: 0.4132 - val_acc: 0.8972\n",
      "- precision: 0.21695112080796705 - recall: 0.8931950219492053 - f1 score: 0.34910657912246273\n",
      "Epoch 39/10000\n",
      "221877/221877 [==============================] - 313s 1ms/step - loss: 0.0562 - acc: 0.9783 - val_loss: 0.4485 - val_acc: 0.8723\n",
      "- precision: 0.18591138263740217 - recall: 0.9284876055807485 - f1 score: 0.3097928414152815\n",
      "Epoch 40/10000\n",
      "221877/221877 [==============================] - 313s 1ms/step - loss: 0.0554 - acc: 0.9785 - val_loss: 0.4389 - val_acc: 0.8789\n",
      "- precision: 0.1852021686100557 - recall: 0.8601625545108152 - f1 score: 0.30478160766124995\n",
      "Epoch 41/10000\n",
      "221877/221877 [==============================] - 313s 1ms/step - loss: 0.0545 - acc: 0.9790 - val_loss: 0.4128 - val_acc: 0.8869\n",
      "- precision: 0.1996355597064884 - recall: 0.8856902771539922 - f1 score: 0.3258289228932487\n",
      "Epoch 42/10000\n",
      "221877/221877 [==============================] - 313s 1ms/step - loss: 0.0534 - acc: 0.9792 - val_loss: 0.4717 - val_acc: 0.8664\n",
      "- precision: 0.16860253769322647 - recall: 0.8466742969734726 - f1 score: 0.28120691853708885\n",
      "Epoch 43/10000\n",
      "221877/221877 [==============================] - 313s 1ms/step - loss: 0.0534 - acc: 0.9796 - val_loss: 0.5146 - val_acc: 0.8681\n",
      "- precision: 0.16761022574798146 - recall: 0.8252611448357794 - f1 score: 0.27863066835261\n",
      "Epoch 44/10000\n",
      "221877/221877 [==============================] - 313s 1ms/step - loss: 0.0518 - acc: 0.9798 - val_loss: 0.5321 - val_acc: 0.8514\n",
      "- precision: 0.16008085752346726 - recall: 0.898352723005375 - f1 score: 0.2717394400608277\n",
      "Epoch 45/10000\n",
      "221877/221877 [==============================] - 313s 1ms/step - loss: 0.0516 - acc: 0.9799 - val_loss: 0.4319 - val_acc: 0.8835\n",
      "- precision: 0.19436668273328248 - recall: 0.882184199469742 - f1 score: 0.318549209787027\n",
      "Epoch 46/10000\n",
      "221877/221877 [==============================] - 313s 1ms/step - loss: 0.0506 - acc: 0.9801 - val_loss: 0.4631 - val_acc: 0.9060\n",
      "- precision: 0.22305532462235886 - recall: 0.8240731350419426 - f1 score: 0.3510818542899203\n",
      "Epoch 47/10000\n",
      "221877/221877 [==============================] - 313s 1ms/step - loss: 0.0495 - acc: 0.9804 - val_loss: 0.4631 - val_acc: 0.8770\n",
      "- precision: 0.18806782575525935 - recall: 0.9000188343016096 - f1 score: 0.31112335353333004\n",
      "Epoch 48/10000\n",
      "221877/221877 [==============================] - 313s 1ms/step - loss: 0.0486 - acc: 0.9807 - val_loss: 0.4630 - val_acc: 0.8808\n",
      "- precision: 0.19409131159011958 - recall: 0.9082189994639468 - f1 score: 0.31983265519572457\n",
      "Epoch 49/10000\n",
      "221877/221877 [==============================] - 313s 1ms/step - loss: 0.0481 - acc: 0.9811 - val_loss: 0.4762 - val_acc: 0.8987\n",
      "- precision: 0.21819515774027878 - recall: 0.8832852817176883 - f1 score: 0.3499446099449543\n",
      "Epoch 50/10000\n",
      "221877/221877 [==============================] - 313s 1ms/step - loss: 0.0484 - acc: 0.9812 - val_loss: 0.4849 - val_acc: 0.8870\n",
      "- precision: 0.2020865019473802 - recall: 0.9028294916187358 - f1 score: 0.3302507247221677\n",
      "Epoch 51/10000\n",
      "221877/221877 [==============================] - 313s 1ms/step - loss: 0.0469 - acc: 0.9814 - val_loss: 0.4850 - val_acc: 0.9014\n",
      "- precision: 0.22276586401229598 - recall: 0.8819234168320704 - f1 score: 0.3556881294133801\n",
      "Epoch 52/10000\n",
      "221877/221877 [==============================] - 313s 1ms/step - loss: 0.0458 - acc: 0.9816 - val_loss: 0.5176 - val_acc: 0.8958\n",
      "- precision: 0.21542771746479752 - recall: 0.9001347376961303 - f1 score: 0.34765238119219083\n",
      "Epoch 53/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.0454 - acc: 0.9819 - val_loss: 0.4879 - val_acc: 0.9061\n",
      "- precision: 0.22403096830758512 - recall: 0.8292453240224273 - f1 score: 0.35275954516039565\n",
      "Epoch 54/10000\n",
      "221877/221877 [==============================] - 313s 1ms/step - loss: 0.0448 - acc: 0.9821 - val_loss: 0.5109 - val_acc: 0.8989\n",
      "- precision: 0.214834205300057 - recall: 0.8572794575721137 - f1 score: 0.3435698235468307\n",
      "Epoch 55/10000\n",
      "221877/221877 [==============================] - 313s 1ms/step - loss: 0.0446 - acc: 0.9821 - val_loss: 0.5119 - val_acc: 0.9021\n",
      "- precision: 0.22420485274369492 - recall: 0.882894107761181 - f1 score: 0.3575997277219008\n",
      "Epoch 56/10000\n",
      "221877/221877 [==============================] - 313s 1ms/step - loss: 0.0440 - acc: 0.9825 - val_loss: 0.5915 - val_acc: 0.8516\n",
      "- precision: 0.15905902609408185 - recall: 0.8886892774872144 - f1 score: 0.2698244425578337\n",
      "Epoch 57/10000\n",
      "221877/221877 [==============================] - 313s 1ms/step - loss: 0.0433 - acc: 0.9826 - val_loss: 0.5627 - val_acc: 0.8690\n",
      "- precision: 0.179491213666803 - recall: 0.9090592990742217 - f1 score: 0.29978977544194935\n",
      "Epoch 58/10000\n",
      "221877/221877 [==============================] - 313s 1ms/step - loss: 0.0425 - acc: 0.9828 - val_loss: 0.5700 - val_acc: 0.8765\n",
      "- precision: 0.18286202054134426 - recall: 0.8659287483882184 - f1 score: 0.3019581889278461\n",
      "Epoch 59/10000\n",
      "221877/221877 [==============================] - 313s 1ms/step - loss: 0.0424 - acc: 0.9828 - val_loss: 0.5343 - val_acc: 0.8781\n",
      "- precision: 0.1905163002989123 - recall: 0.9077119221129188 - f1 score: 0.31493256794728086\n",
      "Epoch 60/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.0421 - acc: 0.9830 - val_loss: 0.5297 - val_acc: 0.9017\n",
      "- precision: 0.22228444274156708 - recall: 0.8741434014748707 - f1 score: 0.3544391542006527\n",
      "Epoch 61/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.0413 - acc: 0.9832 - val_loss: 0.5563 - val_acc: 0.8894\n",
      "- precision: 0.20337613360869175 - recall: 0.886009011488924 - f1 score: 0.330816126711421\n",
      "Epoch 62/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.0414 - acc: 0.9832 - val_loss: 0.5539 - val_acc: 0.9006\n",
      "- precision: 0.2241012439467857 - recall: 0.9017718731437347 - f1 score: 0.3589892954367185\n",
      "Epoch 63/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.0423 - acc: 0.9834 - val_loss: 0.5054 - val_acc: 0.8979\n",
      "- precision: 0.21282660161359485 - recall: 0.8557002738217696 - f1 score: 0.34087262653661915\n",
      "Epoch 64/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.0410 - acc: 0.9836 - val_loss: 0.4975 - val_acc: 0.8962\n",
      "- precision: 0.21558325571010428 - recall: 0.8952812830505773 - f1 score: 0.347490890278465\n",
      "Epoch 65/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.0396 - acc: 0.9838 - val_loss: 0.5654 - val_acc: 0.9018\n",
      "- precision: 0.22318930109246818 - recall: 0.8793735421526158 - f1 score: 0.35601919196659\n",
      "Epoch 66/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.0392 - acc: 0.9839 - val_loss: 0.5366 - val_acc: 0.9060\n",
      "- precision: 0.2283619710992669 - recall: 0.8597279167813627 - f1 score: 0.36086938013488284\n",
      "Epoch 67/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.0388 - acc: 0.9841 - val_loss: 0.5098 - val_acc: 0.9114\n",
      "- precision: 0.24164756796537837 - recall: 0.8753024354200774 - f1 score: 0.3787362086258776\n",
      "Epoch 68/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.0384 - acc: 0.9842 - val_loss: 0.5314 - val_acc: 0.8875\n",
      "- precision: 0.2015450632547065 - recall: 0.8927748721440679 - f1 score: 0.32885148530702746\n",
      "Epoch 69/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.0382 - acc: 0.9843 - val_loss: 0.5271 - val_acc: 0.9106\n",
      "- precision: 0.2428316151202749 - recall: 0.8958028483259204 - f1 score: 0.382087947399644\n",
      "Epoch 70/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.0380 - acc: 0.9844 - val_loss: 0.6093 - val_acc: 0.8884\n",
      "- precision: 0.20521015261568595 - recall: 0.9107254103704562 - f1 score: 0.3349478350757164\n",
      "Epoch 71/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.0378 - acc: 0.9845 - val_loss: 0.5598 - val_acc: 0.9036\n",
      "- precision: 0.22524122683753958 - recall: 0.8708546426553467 - f1 score: 0.3579109703234411\n",
      "Epoch 72/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.0371 - acc: 0.9847 - val_loss: 0.6065 - val_acc: 0.9164\n",
      "- precision: 0.239759631505568 - recall: 0.7873027831302609 - f1 score: 0.36757926777712013\n",
      "Epoch 73/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.0367 - acc: 0.9849 - val_loss: 0.5295 - val_acc: 0.8725\n",
      "- precision: 0.18312704117829856 - recall: 0.9049881923416833 - f1 score: 0.30461444681499544\n",
      "Epoch 74/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.0367 - acc: 0.9849 - val_loss: 0.6134 - val_acc: 0.9094\n",
      "- precision: 0.22823170731707318 - recall: 0.8134245106703563 - f1 score: 0.3564501639562826\n",
      "Epoch 75/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.0370 - acc: 0.9852 - val_loss: 0.6212 - val_acc: 0.8809\n",
      "- precision: 0.19292878682729023 - recall: 0.8981643799892789 - f1 score: 0.31762963873817096\n",
      "Epoch 76/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.0359 - acc: 0.9851 - val_loss: 0.5689 - val_acc: 0.9149\n",
      "- precision: 0.2430679889443365 - recall: 0.8319980296422932 - f1 score: 0.3762226400508383\n",
      "Epoch 77/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.0356 - acc: 0.9852 - val_loss: 0.6123 - val_acc: 0.8835\n",
      "- precision: 0.19290404493805627 - recall: 0.8716804543413065 - f1 score: 0.3158991806657058\n",
      "Epoch 78/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.0357 - acc: 0.9852 - val_loss: 0.6327 - val_acc: 0.9115\n",
      "- precision: 0.22879732580021808 - recall: 0.7873607348275212 - f1 score: 0.35456301051697586\n",
      "Epoch 79/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.0351 - acc: 0.9855 - val_loss: 0.5919 - val_acc: 0.8981\n",
      "- precision: 0.2134187907795407 - recall: 0.8572649696477985 - f1 score: 0.34175628689253656\n",
      "Epoch 80/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.0347 - acc: 0.9856 - val_loss: 0.6508 - val_acc: 0.8935\n",
      "- precision: 0.20426432519415097 - recall: 0.8459643886820335 - f1 score: 0.3290718349427839\n",
      "Epoch 81/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.0346 - acc: 0.9856 - val_loss: 0.6759 - val_acc: 0.8967\n",
      "- precision: 0.20409824991875797 - recall: 0.8098315054402155 - f1 score: 0.32602888339321545\n",
      "Epoch 82/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.0344 - acc: 0.9857 - val_loss: 0.6254 - val_acc: 0.8871\n",
      "- precision: 0.1976128588041892 - recall: 0.8690436521159614 - f1 score: 0.3220046917861534\n",
      "Epoch 83/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.0339 - acc: 0.9859 - val_loss: 0.6184 - val_acc: 0.9068\n",
      "- precision: 0.23036873840445268 - recall: 0.8634947771032844 - f1 score: 0.3637057084361832\n",
      "Epoch 84/10000\n",
      "221877/221877 [==============================] - 312s 1ms/step - loss: 0.0338 - acc: 0.9860 - val_loss: 0.6316 - val_acc: 0.9176\n",
      "- precision: 0.25359918978167695 - recall: 0.859785868478623 - f1 score: 0.39167222159889653\n",
      "Epoch 85/10000\n",
      "  5632/221877 [..............................] - ETA: 4:57 - loss: 0.0339 - acc: 0.9861"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-de8d78f93617>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#g = corpus_training_data_generator('gutenberg',TIME_SLICE_SIZE, BATCH_SIZE, shift=False)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtensor_board\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2659\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2661\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2662\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2663\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2630\u001b[0m                                 session)\n\u001b[1;32m-> 2631\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2632\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#g = corpus_training_data_generator('gutenberg',TIME_SLICE_SIZE, BATCH_SIZE, shift=False)\n",
    "model.fit(X, Y, validation_data=(X_val, Y_val, W_val), callbacks=[tensor_board, f1_score], batch_size=BATCH_SIZE, epochs=EPOCHS, sample_weight=W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Tim Smith Works for Google iN california. Towards Summer The Weather in London Gets Really Warm'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_sentence = \"Tim Smith works for Google in California. Towards summer the weather in London gets really warm\".lower()\n",
    "test_sentence = pad([list(original_sentence)], len(original_sentence))\n",
    "test_sentence = encode_each_sentence(test_sentence, input_feature_to_int_map)\n",
    "\n",
    "mapped_sentence = np.asarray(test_sentence)\n",
    "predicted_result = model.predict_classes(mapped_sentence)[0]\n",
    "print(predicted_result)\n",
    "predicted_result = list(zip(pad([list(original_sentence)], len(original_sentence))[0], predicted_result.tolist()))\n",
    "\n",
    "def true_case(letter, label):\n",
    "    if letter == 0:\n",
    "        return ''\n",
    "    if(label == 0):\n",
    "        return letter.lower()\n",
    "    if (label == 1):\n",
    "        return letter.upper()\n",
    "    return letter\n",
    "\n",
    "predicted_result = [true_case(letter, label) for letter, label in predicted_result]\n",
    "''.join(predicted_result) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"big_lstm.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y.shape)\n",
    "print(W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
